{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14c9d7a",
   "metadata": {},
   "source": [
    "# Step 5.: Machine Learning - Parameter Search / Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63474560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "\n",
    "# Import installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9f8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's mount the Google Drive, where we store files and models (if applicable, otherwise work\n",
    "# locally)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    core_path = \"/gdrive/MyDrive/Colab/asteroid_taxonomy/\"\n",
    "except ModuleNotFoundError:\n",
    "    core_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bc69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the level 2 asteroid data\n",
    "asteroids_df = pd.read_pickle(os.path.join(core_path, \"data/lvl2/\", \"asteroids.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f27a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add a binary classification schema, where we distinguish between e.g., X and non-X classes\n",
    "asteroids_df.loc[:, \"Class\"] = asteroids_df[\"Main_Group\"].apply(lambda x: 1 if x==\"X\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62493261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate the spectra to one array and the classes to another one\n",
    "asteroids_X = np.array([k[\"Reflectance_norm550nm\"].tolist() for k in asteroids_df[\"SpectrumDF\"]])\n",
    "asteroids_y = np.array(asteroids_df[\"Class\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169800d4-82a2-4137-b00e-41dc437ce1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END .............................C=1, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END .............................C=1, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END .............................C=1, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END .............................C=1, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END .............................C=1, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ................................C=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-6-d416bfc52868>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-d416bfc52868>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "# In this example we create a single test-training split with a ratio of 0.8 / 0.2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame([], columns=[])\n",
    "\n",
    "for train_index, test_index in sss.split(asteroids_X, asteroids_y):\n",
    "    \n",
    "    X_train, X_test = asteroids_X[train_index], asteroids_X[test_index]\n",
    "    y_train, y_test = asteroids_y[train_index], asteroids_y[test_index]\n",
    "\n",
    "positive_class_weight = int(1.0 / (sum(y_train) / len(X_train)))\n",
    "    \n",
    "# Compute class weightning\n",
    "positive_class_weight = int(1.0 / (sum(y_train) / len(X_train)))\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [1], 'kernel': ['linear']},\n",
    "  {'C': [1], 'kernel': ['rbf']},\n",
    " ]\n",
    "svc = svm.SVC(class_weight={1: positive_class_weight})\n",
    "\n",
    "# Import the preprocessing module\n",
    "\n",
    "# Instantiate the StandardScaler (mean 0, standard deviation 1) and use the training data to fit\n",
    "# the scaler\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform now the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "wclf = GridSearchCV(svc, param_grid, scoring='f1', verbose=3, cv=5)\n",
    "\n",
    "# Perform the training\n",
    "wclf.fit(X_train_scaled, y_train)\n",
    "\n",
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3aeba75-c7a6-4718-a2d6-27ec0da5f069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455417253712865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wclf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c0d08f-5dea-4595-9041-30201d1a91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf = wclf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6985e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the testing data ...\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ... and perform a predicition\n",
    "y_test_pred = final_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97aa4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201  20]\n",
      " [  0  47]]\n"
     ]
    }
   ],
   "source": [
    "# Import the confusion matrix and perform the computation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(conf_mat)\n",
    "\n",
    "# The order of the confusion matrix is:\n",
    "#     - true negative (top left, tn)\n",
    "#     - false positive (top right, fp)\n",
    "#     - false negative (bottom left, fn)\n",
    "#     - true positive (bottom right, tp)\n",
    "tn, fp, fn, tp = conf_mat.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5686e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 1.0\n",
      "Precision Score: 0.701\n",
      "F1 Score: 0.825\n"
     ]
    }
   ],
   "source": [
    "# Recall: ratio of correctly classified X Class spectra, considering the false negatives\n",
    "# (recall = tp / (tp + fn))\n",
    "recall_score = round(sklearn.metrics.recall_score(y_test, y_test_pred), 3)\n",
    "print(f\"Recall Score: {recall_score}\")\n",
    "\n",
    "# Precision: ratio of correctly classified X Class spectra, considering the false positives\n",
    "# (precision = tp / (tp + fp))\n",
    "precision_score = round(sklearn.metrics.precision_score(y_test, y_test_pred), 3)\n",
    "print(f\"Precision Score: {precision_score}\")\n",
    "\n",
    "# A combined score\n",
    "f1_score = round(sklearn.metrics.f1_score(y_test, y_test_pred), 3)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04c071-e538-4a32-ab25-922ece7a9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize: Apply all data (take care of scaling!) on the training and rerun it. Save it afterwards for further computations\n",
    "# Use https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html for partial fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
